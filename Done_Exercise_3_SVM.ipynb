{"cells":[{"cell_type":"markdown","metadata":{"id":"hNuQqd2YmV03"},"source":["<img src=\"../src/packt-banner.png\" alt=\"\">"]},{"cell_type":"markdown","metadata":{"id":"NmADGEPKmV04"},"source":["### Exercise 3: Build a SVM modle for Face Recognition Problem\n","##### (25 points) --> your total will divided by 5 to get 5 points for this exercise.\n","---\n","\n","We will use a very famous dataset, called Labelled Faces in the Wild, which\n","consists of 1288 faces of famous people, and it is available at http://viswww.cs.umass.edu/lfw/lfw-funneled.tgz. \n","\n","However, note that it can be easily imported via scikit-learn from the datasets class.\n","Each image consists of 1850 features: we could proceed by simply using each of them in the model.\n","\n","\n","\n","Fitting a SVM to non-linear data using the Kernel Trick produces non- linear decision boundaries.\n","In particular, we seek to:\n","* Build SVM model with radial basis function (RBF) kernel\n","* Use a grid search cross-validation to explore ran- dom combinations of parameters."]},{"cell_type":"markdown","metadata":{"id":"BR8Xn-XAmV05"},"source":["### Step to do:"]},{"cell_type":"markdown","metadata":{"id":"bO4pnQdXmV05"},"source":["1. Loading the dataf from sklearn.datasets:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPWAbXW8mV05"},"outputs":[],"source":["from sklearn.datasets import fetch_lfw_people\n","faces = fetch_lfw_people(min_faces_per_person=60)"]},{"cell_type":"markdown","metadata":{"id":"naK6Pwr-mV06"},"source":["2. Since the data can be accessed from the sklearn.datasets module, you need to explore the dataset. \n","    - (refer to the first 6 steps in Lab_1 could help you)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{"id":"ncdk2Q_cmV06"},"source":["a- Print the field names (that is, the keys to the dictionary) (1 point)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"maDYsJPqmV06"},"outputs":[],"source":["# What fields are in the dictionary?\n","\n","for key in faces.keys():\n","    print(key)"]},{"cell_type":"markdown","metadata":{"id":"4Ld-9sJJmV07"},"source":["b- Print the dataset description contained (2 point)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1r6mjnZmV07"},"outputs":[],"source":["# write your code here\n","# Print the dataset description\n","description = faces.DESCR\n","print(description)\n"]},{"cell_type":"markdown","metadata":{"id":"a8WvKTFOmV07"},"source":["3. Print the data, its shape, and the target names. ( 3 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfL6no2FmV07"},"outputs":[],"source":["# What does the data look like?\n","import matplotlib.pyplot as plt\n","\n","images = faces.images\n","\n","target_names = faces.target_names\n","\n","plt.figure(figsize=(10, 5))\n","for i in range(10): \n","    plt.subplot(2, 5, i + 1)\n","    plt.imshow(images[i], cmap='gray')\n","    plt.title(target_names[faces.target[i]])\n","    plt.axis('off')\n","\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qik3fdoQmV08"},"outputs":[],"source":["# what is the shape of the data?\n","data = faces.data\n","data_shape = data.shape\n","print(\"Shape of the Data:\", data_shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aPc9uO-mV08"},"outputs":[],"source":["# What is the target names?\n","target_names = faces.target_names\n","print(\"Target Names (Individuals):\")\n","for name in target_names:\n","    print(name)\n"]},{"cell_type":"markdown","metadata":{"id":"AUDpCWMCmV08"},"source":["4. Divide the data into features (X) using the faces.data and target (y) using faces.target (2 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"06_1FUnMmV08"},"outputs":[],"source":["# Write your code here \n","X = faces.data\n","y = faces.target"]},{"cell_type":"markdown","metadata":{"id":"RGzEfPYImV08"},"source":["5. Splitting the data into training and testing sets. (2 point)\n","\n","We train the model with 70% of the samples and test with the remaining 30%."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izd3Lq1wmV09"},"outputs":[],"source":["# Write your code here \n","\n","from sklearn.model_selection import train_test_split\n","X = faces.data\n","y = faces.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","print(\"Training set - X:\", X_train.shape, \"y:\", y_train.shape)\n","print(\"Testing set - X:\", X_test.shape, \"y:\", y_test.shape)\n","\n","# print the sizes of our training and test set to verify if the splitting has occurred properly.\n","print(\"Training set size (X, y):\", X_train.shape, y_train.shape)\n","print(\"Testing set size (X, y):\", X_test.shape, y_test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"tDQsoYQBmV09"},"source":["6. Declare SVM model with kernel='rbf', class_weight='balanced' (2 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOID8jbUmV09"},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.svm import SVC\n","svm_model = SVC(kernel='rbf', class_weight='balanced')\n","print(svm_model)\n"]},{"cell_type":"markdown","metadata":{"id":"fB84KulSmV09"},"source":["7. Use a grid search cross-validationwith 10 CV to explore random combinations of parameters. (3 points) \n","    - we will adjust C, which controls the margin\n","    - and Gamma (Î³), which controls the size of the radial basis function kernel, and determine the best model."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ZL2TQsEQmV09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Parameters: {'C': 1, 'gamma': 0.001}\n","Best Score: 0.8358688127379716\n"]}],"source":["\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.model_selection import train_test_split\n","param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.001, 0.0005, 0.01, 0.1]}\n","#write your code here\n","faces = fetch_lfw_people(min_faces_per_person=60)\n","\n","X = faces.data\n","y = faces.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","svm_model = SVC(kernel='linear', class_weight='balanced')\n","grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=10)\n","grid_search.fit(X_train, y_train)\n","\n","\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best Score:\", grid_search.best_score_)\n"]},{"cell_type":"markdown","metadata":{"id":"Zo7MRALVmV0-"},"source":["8. predict on the test set, using the best model from above step (best_estimator_) (5 points)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CE6qWljxmV0-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Labels:\n","[3 4 3 6 6 1 3 3 3 1 3 3 4 3 2 1 3 2 3 2 7 7 5 5 0 3 6 7 3 3 0 6 3 3 3 3 2\n"," 3 3 3 3 3 7 1 3 3 0 1 1 2 7 3 4 6 7 3 7 1 7 0 4 3 7 2 5 4 7 3 4 3 1 3 4 1\n"," 3 4 0 4 3 3 1 3 1 0 7 3 3 2 7 1 1 1 2 3 1 7 7 3 3 1 3 7 1 4 3 3 3 3 7 3 3\n"," 1 0 2 3 3 3 2 4 4 7 7 5 3 3 3 3 3 2 2 3 7 0 3 4 3 4 1 3 1 7 6 5 3 3 1 1 3\n"," 5 4 3 3 7 1 7 1 3 4 1 4 6 1 2 3 2 3 1 7 2 2 1 7 3 3 1 1 1 3 3 1 0 0 1 1 7\n"," 1 1 5 3 4 3 3 4 5 6 3 7 3 3 2 2 3 2 3 3 6 3 3 1 7 3 6 1 2 3 1 1 7 6 3 1 3\n"," 1 7 7 2 7 7 5 7 1 3 3 2 4 4 7 3 3 1 3 4 7 1 4 3 1 1 5 4 2 3 4 1 3 1 2 2 3\n"," 7 3 4 3 7 3 1 3 1 3 2]\n"]}],"source":["# write your code here\n","\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","print(\"Predicted Labels:\")\n","print(y_pred)\n"]},{"cell_type":"markdown","metadata":{"id":"I3A5gH2BmV0-"},"source":["9. Model performances:\n","Run the following code to print the model evaluation metric"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"1H51D6V2mV0-"},"outputs":[{"name":"stdout","output_type":"stream","text":["                   precision    recall  f1-score   support\n","\n","     Ariel Sharon       0.70      0.58      0.64        12\n","     Colin Powell       0.84      0.84      0.84        51\n","  Donald Rumsfeld       0.69      0.72      0.71        25\n","    George W Bush       0.86      0.87      0.86        98\n","Gerhard Schroeder       0.65      0.81      0.72        21\n","      Hugo Chavez       1.00      0.67      0.80        15\n","Junichiro Koizumi       0.91      1.00      0.95        10\n","       Tony Blair       0.81      0.79      0.80        38\n","\n","         accuracy                           0.81       270\n","        macro avg       0.81      0.78      0.79       270\n","     weighted avg       0.82      0.81      0.81       270\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","labels = list(faces.target_names)\n","print(classification_report(y_test,y_pred,target_names=labels))"]},{"cell_type":"markdown","metadata":{"id":"xvhPBpEUmV0-"},"source":["10. What do you observe about the model performances? (5 points)\n","\n","#### Write your answer here\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["The model generally has good precision for most classes, with values ranging from 0.65 to 1.00. This suggests that the model's positive predictions are reliable for most classes.\n","The model also exhibits good recall for most classes, with values ranging from 0.58 to 1.00. This suggests that the model is effective at identifying true positive instances for most classes.\n","In this case, the F1-scores range from 0.64 to 0.95, which suggests that the model maintains a good balance between precision and recall for most classes."]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"interpreter":{"hash":"9be90a182e443121e767cfcadea61fa0eeced8ec62a9bd8ae9861f6c1d839655"},"kernelspec":{"display_name":"Python 3.9.5 ('venvml')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
